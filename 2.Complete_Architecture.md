# Architecture

There are 6 main architecture layers in my project

1. Presentation layer :

ui.py - Which handles the session and is user friendly. The input passes from the ui as the voice to the tts_stt.py via the function.

in tts_tts, the speech to text is performed by deepgram.

2. Core application layer :

app.py - Manages the workflow of the agents(adges), nodes and updating the state when intented.

3. State management layer :

state.py - has AgentState class which holds all the variables.

It also holds the confidence score(additional), used to prioritize the agent's response.

4. Agent layer :

- optimistic.py : Very positive and optimistic to the user's query.

- planner.py : Great planner irrespective of the theme of the query. It also acts as an expert agent at the end to combine the state and give the final output.

- realistic.py : Well grounded and relies on facts.

5. Memory layer(Internal) :

- memory.py : It is used to manage the current flow. It combines the buffer and the vector space.

- memory_store.py : Enables persistant conversation, does semantic searches, retrieves similar conversations from the past.

6. External layer

- websearch.py : involves searching externally from the websites and search engine.

For the exact flow, refer "Architecture_flow.jpg".

**Internal and external layer together:**

It enables fetching real time data(through live search) + from vector space(for past convo, to maintain and remember the flow).

*It follows decentralized architecture where the three nodes are involved in the execution. Here, **nodes are the agents and edges are the workflow sequence.*** 

**Tech stack**

- LangGraph : to control the flow and for stateful interactions.

- LangChain : for conversational flow and context aware state.

- Deepgram : real time STT.

- Pinecone : to store vector embeddings. Supports in semantic search.

- Model used : gemini-1.5-pro-latest from gemini, and embedding-001 for embedding the chunks.

- Serper : for web search and real time result fetching.

APIs used:

1. google gemini

2. serper

3. pinecone

4. deepgram

**Implementation of RAG and Vector memory storage:**

- Here, the three agents mentioned use the knowledge base and the external tool as well(as instructed).

- Konwledge base is accessed by implementing embeddings in pinecone (stored and retrieved by semantic search).

- External tool to fetch real time data is handled by serper.

  OVERALL - Knowledge base + External tool integration.

Agent to agent handsoffs : Via shared space between the three agents.

**Flow of the data:**

---

USER INPUT -> SPEECH TO TEXT(by deepgram) -> STATE UPDATE -> 3 AGENTS ACCESS THE SHARED MEMORY STATE -> RESPONSE IS GENERATED -> TEXT TO SPEECH -> READ ALOUD in UI.

---




